// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package llm_service.llm_service


object TextGeneratorGrpc {
  val METHOD_GET_MESSAGE: _root_.io.grpc.MethodDescriptor[llm_service.llm_service.QueryRequest, llm_service.llm_service.QueryResponse] =
    _root_.io.grpc.MethodDescriptor.newBuilder()
      .setType(_root_.io.grpc.MethodDescriptor.MethodType.UNARY)
      .setFullMethodName(_root_.io.grpc.MethodDescriptor.generateFullMethodName("llm_service.TextGenerator", "GetMessage"))
      .setSampledToLocalTracing(true)
      .setRequestMarshaller(_root_.scalapb.grpc.Marshaller.forMessage[llm_service.llm_service.QueryRequest])
      .setResponseMarshaller(_root_.scalapb.grpc.Marshaller.forMessage[llm_service.llm_service.QueryResponse])
      .setSchemaDescriptor(_root_.scalapb.grpc.ConcreteProtoMethodDescriptorSupplier.fromMethodDescriptor(llm_service.llm_service.LlmServiceProto.javaDescriptor.getServices().get(0).getMethods().get(0)))
      .build()
  
  val SERVICE: _root_.io.grpc.ServiceDescriptor =
    _root_.io.grpc.ServiceDescriptor.newBuilder("llm_service.TextGenerator")
      .setSchemaDescriptor(new _root_.scalapb.grpc.ConcreteProtoFileDescriptorSupplier(llm_service.llm_service.LlmServiceProto.javaDescriptor))
      .addMethod(METHOD_GET_MESSAGE)
      .build()
  
  trait TextGenerator extends _root_.scalapb.grpc.AbstractService {
    override def serviceCompanion = TextGenerator
    /** get the message from the AWS Bedrock's LLM
      */
    def getMessage(request: llm_service.llm_service.QueryRequest): scala.concurrent.Future[llm_service.llm_service.QueryResponse]
  }
  
  object TextGenerator extends _root_.scalapb.grpc.ServiceCompanion[TextGenerator] {
    implicit def serviceCompanion: _root_.scalapb.grpc.ServiceCompanion[TextGenerator] = this
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.ServiceDescriptor = llm_service.llm_service.LlmServiceProto.javaDescriptor.getServices().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.ServiceDescriptor = llm_service.llm_service.LlmServiceProto.scalaDescriptor.services(0)
    def bindService(serviceImpl: TextGenerator, executionContext: scala.concurrent.ExecutionContext): _root_.io.grpc.ServerServiceDefinition =
      _root_.io.grpc.ServerServiceDefinition.builder(SERVICE)
      .addMethod(
        METHOD_GET_MESSAGE,
        _root_.io.grpc.stub.ServerCalls.asyncUnaryCall(new _root_.io.grpc.stub.ServerCalls.UnaryMethod[llm_service.llm_service.QueryRequest, llm_service.llm_service.QueryResponse] {
          override def invoke(request: llm_service.llm_service.QueryRequest, observer: _root_.io.grpc.stub.StreamObserver[llm_service.llm_service.QueryResponse]): _root_.scala.Unit =
            serviceImpl.getMessage(request).onComplete(scalapb.grpc.Grpc.completeObserver(observer))(
              executionContext)
        }))
      .build()
  }
  
  trait TextGeneratorBlockingClient {
    def serviceCompanion = TextGenerator
    /** get the message from the AWS Bedrock's LLM
      */
    def getMessage(request: llm_service.llm_service.QueryRequest): llm_service.llm_service.QueryResponse
  }
  
  class TextGeneratorBlockingStub(channel: _root_.io.grpc.Channel, options: _root_.io.grpc.CallOptions = _root_.io.grpc.CallOptions.DEFAULT) extends _root_.io.grpc.stub.AbstractStub[TextGeneratorBlockingStub](channel, options) with TextGeneratorBlockingClient {
    /** get the message from the AWS Bedrock's LLM
      */
    override def getMessage(request: llm_service.llm_service.QueryRequest): llm_service.llm_service.QueryResponse = {
      _root_.scalapb.grpc.ClientCalls.blockingUnaryCall(channel, METHOD_GET_MESSAGE, options, request)
    }
    
    override def build(channel: _root_.io.grpc.Channel, options: _root_.io.grpc.CallOptions): TextGeneratorBlockingStub = new TextGeneratorBlockingStub(channel, options)
  }
  
  class TextGeneratorStub(channel: _root_.io.grpc.Channel, options: _root_.io.grpc.CallOptions = _root_.io.grpc.CallOptions.DEFAULT) extends _root_.io.grpc.stub.AbstractStub[TextGeneratorStub](channel, options) with TextGenerator {
    /** get the message from the AWS Bedrock's LLM
      */
    override def getMessage(request: llm_service.llm_service.QueryRequest): scala.concurrent.Future[llm_service.llm_service.QueryResponse] = {
      _root_.scalapb.grpc.ClientCalls.asyncUnaryCall(channel, METHOD_GET_MESSAGE, options, request)
    }
    
    override def build(channel: _root_.io.grpc.Channel, options: _root_.io.grpc.CallOptions): TextGeneratorStub = new TextGeneratorStub(channel, options)
  }
  
  object TextGeneratorStub extends _root_.io.grpc.stub.AbstractStub.StubFactory[TextGeneratorStub] {
    override def newStub(channel: _root_.io.grpc.Channel, options: _root_.io.grpc.CallOptions): TextGeneratorStub = new TextGeneratorStub(channel, options)
    
    implicit val stubFactory: _root_.io.grpc.stub.AbstractStub.StubFactory[TextGeneratorStub] = this
  }
  
  def bindService(serviceImpl: TextGenerator, executionContext: scala.concurrent.ExecutionContext): _root_.io.grpc.ServerServiceDefinition = TextGenerator.bindService(serviceImpl, executionContext)
  
  def blockingStub(channel: _root_.io.grpc.Channel): TextGeneratorBlockingStub = new TextGeneratorBlockingStub(channel)
  
  def stub(channel: _root_.io.grpc.Channel): TextGeneratorStub = new TextGeneratorStub(channel)
  
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.ServiceDescriptor = llm_service.llm_service.LlmServiceProto.javaDescriptor.getServices().get(0)
  
}